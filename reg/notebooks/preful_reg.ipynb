{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc461019-1e9d-4950-90c6-674486eff0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "import pydicom\n",
    "import glob\n",
    "import torch\n",
    "from pathlib2 import Path\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2296f3-9b08-470a-9af6-50ef44d5c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import normalize, standardize, reader\n",
    "from model import TransMorphModule\n",
    "from utils import load_losses, load_model_params\n",
    "from models.modules.spatial_transformer import SpatialTransformerSeries\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53db83-63f6-457d-a4de-3fa5af8d0741",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_best_model(ckpt_dir):\n",
    "    ckpt_dir = Path(ckpt_dir)\n",
    "    ckpt_file_names = sorted([c.name for c in ckpt_dir.glob(\"*.ckpt\")], reverse=True)\n",
    "    \n",
    "    best_ckpt = ckpt_dir / ckpt_file_names[0]\n",
    "    val_loss, epoch = ckpt_file_names[0].split(\"&\")\n",
    "    val_loss = val_loss.split(\"=\")[1]\n",
    "    epoch = epoch.split(\"=\")[1].split(\".\")[0]\n",
    "\n",
    "    ident = str(ckpt_dir.name).split(\"-\")\n",
    "    if len(ident) == 9:\n",
    "        model_name, image_loss, flow_loss, optimizer_name, lr, target_type, max_epoch, series_len, data_mod = ident\n",
    "    else:\n",
    "        model_name, model_ver, image_loss, flow_loss, optimizer_name, lr, target_type, max_epoch, series_len, data_mod = ident\n",
    "        model_name = f\"{model_name}-{model_ver}\"\n",
    "\n",
    "    target_type = str.lower(target_type)\n",
    "    series_len = int(series_len)\n",
    "    max_epoch = int(max_epoch)\n",
    "\n",
    "    image_losses, flow_losses = load_losses(image_loss, flow_loss, delimiter=\"=\")\n",
    "    \n",
    "    net, criteria_image, criteria_flow, criterion_disp, optimizer = load_model_params(\n",
    "        model_name=model_name,\n",
    "        image_losses=image_losses,\n",
    "        flow_losses=flow_losses,\n",
    "        optimizer_name=None,\n",
    "        series_len=series_len)\n",
    "\n",
    "    model = TransMorphModule.load_from_checkpoint(\n",
    "        str(best_ckpt),\n",
    "        strict=False,\n",
    "        net=net,\n",
    "        criteria_image=criteria_image,\n",
    "        criteria_flow=criteria_flow,\n",
    "        criterion_disp=criterion_disp,\n",
    "        target_type=target_type,\n",
    "    )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Best performing model\")\n",
    "    print(\"\")\n",
    "    print(f\"    val_loss    : {val_loss}\")\n",
    "    print(f\"    epoch       : {epoch}\")\n",
    "    print(\"\")\n",
    "    print(f\"    model_name  : {model_name}\")\n",
    "    print(f\"    image_loss  : {criteria_image}\")\n",
    "    print(f\"    flow_loss   : {criteria_flow}\")\n",
    "    print(f\"    disp_loss   : {criterion_disp}\")\n",
    "    print(f\"    target_type : {target_type}\")\n",
    "    print(f\"    max_epoch   : {max_epoch}\")\n",
    "    print(f\"    series_len  : {series_len}\")\n",
    "    print(f\"    data_mod    : {data_mod}\")\n",
    "    print(\"\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return model, data_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a463fef-249c-4f20-b4db-58dfe366df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpkt = \"model_weights_v2/transmorph-gmi=1-gl2d=1-adam-0.0001-last-100-32-norm/\"\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"No cuda :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab410e-3d09-4098-8f85-704d4f23ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_folders = glob.glob(\"/media/agjvc_rad3/_TESTKOLLEKTIV/Daten/Daten/*/Series*\")\n",
    "series_paths = [Path(p) for p in series_folders]\n",
    "model, data_mod = load_best_model(cpkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f34c99-9eae-4ae8-84f2-55c78ad8896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7f0c3-0a52-49cb-bcde-becc872eab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for series_path_dir in series_paths:\n",
    "    print(80 * \"=\")\n",
    "    print(f\"series_path_dir = {series_path_dir}\")\n",
    "\n",
    "    reg_path_dir = series_path_dir / \"images_reg_av_transmorph\"\n",
    "    print(f\"reg_path_dir = {reg_path_dir}\")\n",
    "\n",
    "    if not os.path.exists(reg_path_dir):\n",
    "        os.makedirs(reg_path_dir)\n",
    "    else:\n",
    "        print(\"  -> reg_path_dir already exists\")\n",
    "\n",
    "    dicoms_mat_path = series_path_dir / \"dicoms.mat\"\n",
    "    print(f\"dicoms_mat_path = {dicoms_mat_path}\")\n",
    "\n",
    "    data, mat = reader(dicoms_mat_path, mat=True)\n",
    "    ndat = data\n",
    "    if data_mod == \"std\":\n",
    "        ndat = standardize(data)\n",
    "    if data_mod == \"norm\":\n",
    "        ndat = normalize(data)\n",
    "    \n",
    "    sample = torch.from_numpy(ndat.astype(np.float32)).unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        _, flows, _ = model(sample)\n",
    "\n",
    "    del ndat\n",
    "    del sample\n",
    "\n",
    "    sample = torch.from_numpy(data.astype(np.float32)).unsqueeze(0).cuda()\n",
    "    stn = SpatialTransformerSeries(sample.shape[2:]).cuda()\n",
    "    warped = stn(sample, flows)\n",
    "    \n",
    "    del stn\n",
    "    del sample\n",
    "    del flows\n",
    "    \n",
    "    dcm = warped.view(warped.shape[2:]).permute(2,0,1).detach().cpu().numpy()\n",
    "    del warped\n",
    "\n",
    "    mat[\"dcm\"] = dcm\n",
    "    del dcm\n",
    "\n",
    "    reg_result_path = reg_path_dir / \"dicoms.mat\"\n",
    "    print(f\"reg_result_path = {reg_result_path}\")\n",
    "    spio.savemat(reg_result_path , mat, long_field_names=True)\n",
    "\n",
    "    shutil.copyfile(series_path_dir / 'images_reg_av/dicomsNumber.mat', reg_path_dir / 'dicomsNumber.mat')\n",
    "\n",
    "    dicom_path = reg_path_dir / \"IM-0001-0001.dcm\"\n",
    "    print(f\"dicom_path = {dicom_path}\")\n",
    "\n",
    "    shutil.copyfile(series_path_dir / \"images_reg_av/IM-0001-0001.dcm\", dicom_path)\n",
    "    ds = pydicom.dcmread(dicom_path)\n",
    "    data = mat['dcm'][0,:,:]\n",
    "    ds.PixelData = data.tobytes()\n",
    "    ds.save_as(dicom_path)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "    print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
