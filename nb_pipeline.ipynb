{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684006a-5bd0-4176-9820-ba6c860a7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, torch\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        samples = glob.glob(\"/media/agjvc_rad3/_TESTKOLLEKTIV/Daten/Daten/*\")\n",
    "        series = [glob.glob(os.path.join(sample, \"Series*/dicoms.mat\")) for sample in samples]\n",
    "        slices = [s[int(len(s) / 2)] for s in series if len(s) > 0]\n",
    "        self.slices = slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.slices[idx]\n",
    "        dcm = spio.loadmat(path)[\"dcm\"].astype(np.int32)[:192] # must be int32 as uint16 is not supported and 32bit required for safe upcast\n",
    "        dcm = (dcm / 255).astype(np.float32)\n",
    "        tensor = torch.from_numpy(dcm)\n",
    "        x = torch.permute(tensor, (1,2,0))[None, :, :, :] # C, W, H, t\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ecf7f7-8786-4d5c-a952-1988e35a204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = LungDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a5fd9a-c8eb-452a-82e6-179564f92df6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%script echo \"SKIP\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = LungDataset()\n",
    "sample = dataset[10]\n",
    "print(sample.shape)\n",
    "print(sample.dtype)\n",
    "fig, ax = plt.subplots(3, 10, figsize=(30, 10))\n",
    "for i in range(3):\n",
    "    for j in range(10):\n",
    "        f = sample[:,:,:, i * j + j]\n",
    "        ax[i][j].imshow(f.view(256,256), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe4f81-e692-4c58-bc79-dc027f95f546",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "class LungDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=1, num_workers=1, pin_memory=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.pin_memory = pin_memory\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.dataset = None\n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "        self.test_data = None\n",
    "    \n",
    "    def prepare_date(self):\n",
    "        # not needed as the data is not downloaded\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = LungDataset()\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "        total_len = len(self.dataset)\n",
    "        train_len = int(total_len * 0.8)\n",
    "        val_len = int(total_len * 0.1)\n",
    "        test_len = total_len - (train_len + val_len)\n",
    "        \n",
    "        self.train_data, self.val_data, self.test_data = random_split(\n",
    "            dataset = self.dataset, \n",
    "            lengths = [train_len, val_len, test_len], \n",
    "            generator = generator\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, pin_memory=self.pin_memory, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size, pin_memory=self.pin_memory, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, pin_memory=self.pin_memory, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b600537",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class NCC_vxm(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Local (over window) normalized cross correlation loss.<\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, win=None):\n",
    "        super(NCC_vxm, self).__init__()\n",
    "        self.win = win\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "\n",
    "        Ii = y_true\n",
    "        Ji = y_pred\n",
    "\n",
    "        # get dimension of volume\n",
    "        # assumes Ii, Ji are sized [batch_size, *vol_shape, nb_feats]\n",
    "        ndims = len(list(Ii.size())) - 2\n",
    "        assert ndims in [1, 2, 3], \"volumes should be 1 to 3 dimensions. found: %d\" % ndims\n",
    "\n",
    "        # set window size\n",
    "        win = [9] * ndims if self.win is None else self.win\n",
    "\n",
    "        # compute filters\n",
    "        sum_filt = torch.ones([1, 1, *win]).to(\"cuda\")\n",
    "\n",
    "        pad_no = math.floor(win[0] / 2)\n",
    "\n",
    "        if ndims == 1:\n",
    "            stride = (1)\n",
    "            padding = (pad_no)\n",
    "        elif ndims == 2:\n",
    "            stride = (1, 1)\n",
    "            padding = (pad_no, pad_no)\n",
    "        else:\n",
    "            stride = (1, 1, 1)\n",
    "            padding = (pad_no, pad_no, pad_no)\n",
    "\n",
    "        # get convolution function\n",
    "        conv_fn = getattr(torch.nn.functional, 'conv%dd' % ndims)\n",
    "\n",
    "        # compute CC squares\n",
    "        I2 = Ii * Ii\n",
    "        J2 = Ji * Ji\n",
    "        IJ = Ii * Ji\n",
    "\n",
    "        I_sum = conv_fn(Ii, sum_filt, stride=stride, padding=padding)\n",
    "        J_sum = conv_fn(Ji, sum_filt, stride=stride, padding=padding)\n",
    "        I2_sum = conv_fn(I2, sum_filt, stride=stride, padding=padding)\n",
    "        J2_sum = conv_fn(J2, sum_filt, stride=stride, padding=padding)\n",
    "        IJ_sum = conv_fn(IJ, sum_filt, stride=stride, padding=padding)\n",
    "\n",
    "        win_size = np.prod(win)\n",
    "        u_I = I_sum / win_size\n",
    "        u_J = J_sum / win_size\n",
    "\n",
    "        cross = IJ_sum - u_J * I_sum - u_I * J_sum + u_I * u_J * win_size\n",
    "        I_var = I2_sum - 2 * u_I * I_sum + u_I * u_I * win_size\n",
    "        J_var = J2_sum - 2 * u_J * J_sum + u_J * u_J * win_size\n",
    "\n",
    "        cc = cross * cross / (I_var * J_var + 1e-5)\n",
    "\n",
    "        return -torch.mean(cc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4159f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SpatialTransformer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    N-D Spatial Transformer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, mode='bilinear'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        # create sampling grid\n",
    "        vectors = [torch.arange(0, s) for s in size]\n",
    "        grids = torch.meshgrid(vectors)\n",
    "        grid = torch.stack(grids)\n",
    "        grid = torch.unsqueeze(grid, 0)\n",
    "        grid = grid.type(torch.FloatTensor).cuda()\n",
    "\n",
    "        # registering the grid as a buffer cleanly moves it to the GPU, but it also\n",
    "        # adds it to the state dict. this is annoying since everything in the state dict\n",
    "        # is included when saving weights to disk, so the model files are way bigger\n",
    "        # than they need to be. so far, there does not appear to be an elegant solution.\n",
    "        # see: https://discuss.pytorch.org/t/how-to-register-buffer-without-polluting-state-dict\n",
    "        self.register_buffer('grid', grid)\n",
    "\n",
    "    def forward(self, src, flow):\n",
    "        # new locations\n",
    "        new_locs = self.grid + flow\n",
    "        shape = flow.shape[2:]\n",
    "\n",
    "        # need to normalize grid values to [-1, 1] for resampler\n",
    "        for i in range(len(shape)):\n",
    "            new_locs[:, i, ...] = 2 * (new_locs[:, i, ...] / (shape[i] - 1) - 0.5)\n",
    "\n",
    "        # move channels dim to last position\n",
    "        # also not sure why, but the channels need to be reversed\n",
    "        if len(shape) == 2:\n",
    "            new_locs = new_locs.permute(0, 2, 3, 1)\n",
    "            new_locs = new_locs[..., [1, 0]]\n",
    "        elif len(shape) == 3:\n",
    "            new_locs = new_locs.permute(0, 2, 3, 4, 1)\n",
    "            new_locs = new_locs[..., [2, 1, 0]]\n",
    "\n",
    "        return torch.nn.functional.grid_sample(src, new_locs, align_corners=True, mode=self.mode)\n",
    "\n",
    "class register_model(torch.nn.Module):\n",
    "    def __init__(self, img_size=(64, 256, 256), mode='bilinear'):\n",
    "        super(register_model, self).__init__()\n",
    "        self.spatial_trans = SpatialTransformer(img_size, mode)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img = x[0].cuda()\n",
    "        flow = x[1].cuda()\n",
    "        out = self.spatial_trans(img, flow)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2291a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "max_epoch = 10\n",
    "lr = 1e-4\n",
    "weights = [1]\n",
    "criterions = [NCC_vxm()]\n",
    "\n",
    "pl.seed_everything(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class TransMorphModel(pl.LightningModule):\n",
    "    def __init__(self, model, stn):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.stn = stn\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        target = batch[:,:,:,-1] # always use last image in a seq.\n",
    "        output = self.model(batch)\n",
    "        loss = 0\n",
    "        loss_vals = []\n",
    "        for n, loss_fn in enumerate(criterions):\n",
    "            curr_loss = loss_fn(output[n], target) * weights[n]\n",
    "            loss_vals.append(curr_loss)\n",
    "            loss += curr_loss\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # TODO: track val loss\n",
    "        pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afd084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transmorph.models import TransMorph\n",
    "from transmorph.models.TransMorph import CONFIGS as CONFIGS_TM\n",
    "\n",
    "config = CONFIGS_TM[\"TransMorph-Tiny\"]\n",
    "model = TransMorph.TransMorph(config)\n",
    "reg_model = register_model(config.img_size, 'nearest')\n",
    "\n",
    "plmodel = TransMorphModel(model, reg_model)\n",
    "trainer = pl.Trainer(max_epochs=max_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = LungDataModule(batch_size=1, num_workers=4, pin_memory=True)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "trainer.fit(plmodel, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a004f78-17e0-456c-8d55-fe490ffa8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"first_fit.ckpt\")\n",
    "# new_model = MyModel.load_from_checkpoint(checkpoint_path=\"example.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e37f88-a1ba-4866-8a88-929ee11eb42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
