{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb56f8d68c923a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "PARAM_NAME = \"context_length\"\n",
    "TEST_NAME = \"temporal_loss\"\n",
    "SAMPLE_IDX = 1\n",
    "WANDB_PROJECT = \"temple/lung-registration\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c0295920dce081",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19c88917b3914d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from reg.transmorph import TransMorphModule\n",
    "from reg.data import LungDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeaaaa8a1d07e8d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Series export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38b2d88ba9d04f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31ca5476bb42a0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def sorted_files_in_directory(directory: str):\n",
    "    run_ids = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    runs = [(d, os.path.join(directory, d)) for d in run_ids]\n",
    "    files = [(run_id, sorted(os.listdir(path_suffix), reverse=True)) for run_id, path_suffix in runs]\n",
    "    files_best = [(run_id, ff[0]) for run_id, ff in files]\n",
    "    return files_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac0fd0ea1f13296",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_best_model(model_path: str):\n",
    "    model = TransMorphModule.load_from_checkpoint(str(model_path), strict=True)\n",
    "    print(f\"{'=' * 5} Configuration summary {'=' * 92}\")\n",
    "    print(f\"\")\n",
    "    print(model.hparams)\n",
    "    print(f\"\")\n",
    "    print(\"=\" * 120)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8bae0d1d48bd6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def setup_data_module():\n",
    "    n_available_cores = len(os.sched_getaffinity(0)) - 1\n",
    "    n_available_cores = 1 if n_available_cores == 0 else n_available_cores\n",
    "    data_module = LungDataModule(\n",
    "        root_dir=\"/media/agjvc_rad3/_TESTKOLLEKTIV/Daten/Daten\",\n",
    "        split=(0.7, 0.1, 0.2),\n",
    "        seed=42,\n",
    "        pin_memory=True,\n",
    "        num_workers=n_available_cores,\n",
    "    )\n",
    "    data_module.setup()\n",
    "    return data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5808b577641b85",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_diff_series(warped_series: torch.Tensor):\n",
    "    zero = torch.zeros(warped_series[0].shape).cuda()\n",
    "    abs_diff_series_a = torch.stack([torch.abs(warped_series[i] - warped_series[i + 1]) for i in range(warped_series.shape[0] - 1)] + [zero], dim=0)\n",
    "    abs_diff_series_b = torch.stack([zero] + [torch.abs(warped_series[i - 1] - warped_series[i]) for i in range(1, warped_series.shape[0])], dim=0)\n",
    "    return (abs_diff_series_a + abs_diff_series_b) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63b2f8d7322492",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_flow_series(flow_series: torch.Tensor):\n",
    "    flow_series = torch.tanh(flow_series[:, :, :])\n",
    "    flows_x = (flow_series[:, :, :, 0] + 1) / 2\n",
    "    flows_y = (flow_series[:, :, :, 1] + 1) / 2\n",
    "    flows_z = flows_x * 0\n",
    "    flow_series = torch.stack([flows_x, flows_y, flows_z], dim=-1)\n",
    "    return flow_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14b95c5e854da1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def fetch_sample_from_dataloader(dataloader, sample_idx):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i == sample_idx or sample_idx is None:\n",
    "            return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d8f5b581370ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def add_text_to_image(image, text, position=(10, 10), font_size=20, color=(255, 255, 255)):\n",
    "    pil_img = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "\n",
    "    return np.array(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4739625fb68cb48d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def save_images_to_directory(directory, images, cmap):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for idx, img in tqdm(enumerate(images), total=images.shape[0]):\n",
    "        img_path = os.path.join(directory, f\"{idx:0>3}.png\")\n",
    "\n",
    "        if cmap is not None:\n",
    "            if img.ndim == 3 and img.shape[2] == 1:\n",
    "                img = img.cpu().numpy()[:, :, 0]\n",
    "            plt.imsave(img_path, img, cmap=cmap)\n",
    "        else:\n",
    "            # Save the image directly if no colormap is used\n",
    "            img = img.permute(2, 0, 1)  # Change shape to (C, H, W)\n",
    "            save_image(img, img_path)\n",
    "\n",
    "        # Add the index as text to the image\n",
    "        img = Image.open(img_path)\n",
    "        img = add_text_to_image(np.array(img), f\"{idx:0>3}\")\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed0300c871cde1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Series export main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3a8c230587a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def main_series_export(test_name, sample_idx=None):\n",
    "    model_path = f\"../model_weights/test_{test_name}\"\n",
    "    eval_path = f\"../model_eval/test_{test_name}\"\n",
    "\n",
    "    data_module = setup_data_module()\n",
    "    dataloader = data_module.test_dataloader()\n",
    "\n",
    "    if sample_idx is None:\n",
    "        sample_idx = np.random.randint(0, 64)\n",
    "\n",
    "    dim = (3, 1, 2, 0)\n",
    "    moving_series = fetch_sample_from_dataloader(dataloader, sample_idx).cuda()\n",
    "    moving_series_exp = moving_series[0].permute(dim)\n",
    "    \n",
    "    all_runs = sorted_files_in_directory(model_path)\n",
    "    for run_id, path_suffix in all_runs:\n",
    "        run_model_path = os.path.join(os.path.join(model_path, run_id), path_suffix)\n",
    "    \n",
    "        # 1. Load best model\n",
    "        model = load_best_model(run_model_path)\n",
    "\n",
    "        # 2. Extract predictions and inputs\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            warped_series, flow_series = model(moving_series)\n",
    "    \n",
    "        warped_series = warped_series[0].permute(dim)\n",
    "        flow_series = flow_series[0].permute(dim)\n",
    "    \n",
    "        # 3. Compute series difference\n",
    "        diff_series = compute_diff_series(warped_series)\n",
    "    \n",
    "        # 4. Transform flow series\n",
    "        transformed_flow = compute_flow_series(flow_series)\n",
    "    \n",
    "        # 5. Save images and video\n",
    "        arr = [\n",
    "            (moving_series_exp, \"moving_series\", None),\n",
    "            (warped_series, \"warped_series\", None),\n",
    "            (transformed_flow, \"flow_series\", None),\n",
    "            (diff_series, \"diff_series\", \"magma\")\n",
    "        ]\n",
    "    \n",
    "        for images, name, cmap in arr:\n",
    "            save_images_to_directory(f\"{eval_path}/{run_id}/{name}\", images, cmap)\n",
    "\n",
    "        del warped_series, flow_series, transformed_flow, diff_series\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabaee1d1d9c5cc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "main_series_export(TEST_NAME, SAMPLE_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db01108a37c608",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Series mean intensity histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa716239391a504",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def histogram_main(sample_idx):\n",
    "    CUT_OFF = 30\n",
    "\n",
    "    data_module = setup_data_module()\n",
    "    dataloader = data_module.test_dataloader()\n",
    "\n",
    "    if sample_idx is None:\n",
    "        sample_idx = np.random.randint(0, 64)\n",
    "\n",
    "    moving_series = fetch_sample_from_dataloader(dataloader, sample_idx)\n",
    "\n",
    "    image_means = moving_series.mean(axis=(2, 3))[0, 0][CUT_OFF:]\n",
    "    mean_of_means = torch.mean(image_means)\n",
    "    std_of_means = torch.std(image_means)  # Calculate the standard deviation of the means\n",
    "    diff = torch.abs(image_means - mean_of_means)\n",
    "    _, max_diff_i = torch.topk(diff, 1, largest=True)\n",
    "    _, mean_i = torch.topk(diff, 1, largest=False)\n",
    "    _, max_i = torch.topk(image_means, 1)\n",
    "\n",
    "    image_indices = np.array(list(range(0, len(image_means)))) + CUT_OFF\n",
    "\n",
    "    figsize = (16, 5)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    ax.set_title(\"Mean of Image Series\")\n",
    "    ax.set_xlabel(\"Image Index\")\n",
    "    ax.set_ylabel(\"Mean Value\")\n",
    "\n",
    "    ax.plot(image_indices, image_means, \"-\", color='b', lw=2, label=\"Image Means\")\n",
    "    ax.axvline(x=(max_diff_i + CUT_OFF).numpy()[0], color='r', linestyle='-', lw=2, label=f\"Peak at idx = {(max_diff_i + CUT_OFF).numpy()[0]}\")\n",
    "    ax.axhline(y=image_means[-1], color='purple', linestyle=\"dashed\", lw=2, label=\"Last Mean\")\n",
    "    ax.axhline(y=image_means[mean_i], color='green', linestyle=\"dashdot\", lw=2, label=\"Mean of Means\")\n",
    "    ax.axhline(y=image_means[max_i], color='orange', linestyle=\"dotted\", lw=2, label=\"Max Mean\")\n",
    "\n",
    "    # Plot sigma lines\n",
    "    ax.axhline(y=mean_of_means + std_of_means, color='y', linestyle=\"dotted\", lw=2, label=\"Mean + 1 Sigma\")\n",
    "    ax.axhline(y=mean_of_means - std_of_means, color='y', linestyle=\"dotted\", lw=2, label=\"Mean - 1 Sigma\")\n",
    "    ax.axhline(y=mean_of_means + 2 * std_of_means, color='orange', linestyle=\"dotted\", lw=2, label=\"Mean + 2 Sigma\")\n",
    "    ax.axhline(y=mean_of_means - 2 * std_of_means, color='orange', linestyle=\"dotted\", lw=2, label=\"Mean - 2 Sigma\")\n",
    "\n",
    "    # Set x-axis ticks every 10 values\n",
    "    ax.set_xticks(np.arange(image_indices[0], image_indices[-1] + 1, 10))\n",
    "\n",
    "    # Draw vertical lines every 32 steps\n",
    "    for x in range(image_indices[0], image_indices[-1] + 1, 32):\n",
    "        ax.axvline(x=x, color='gray', linestyle='--', lw=1, label='Every 32 Steps' if x == image_indices[0] else \"\")\n",
    "\n",
    "    ax.legend(loc='lower right', fontsize='small')\n",
    "    ax.grid(True, which='both', linestyle='--', lw=0.5)\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f753f7d258c3c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "histogram_main(SAMPLE_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2342e04400ec91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Series animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba2c1128ee6816",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0aaec9ce6abb1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load_images(base_path, targets, runs):\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        run_data = []\n",
    "        for target in targets:\n",
    "            target_path = os.path.join(base_path, run, target)\n",
    "            images = []\n",
    "            for img_name in sorted(os.listdir(target_path)):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img_path = os.path.join(target_path, img_name)\n",
    "                    img = Image.open(img_path)\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "            run_data.append(images)\n",
    "        data.append(run_data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8ce43a3ad59ff",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def series_anim_main(test_name):\n",
    "    base_path = f\"../model_eval/test_{test_name}\"\n",
    "    targets = [\"moving_series\", \"warped_series\", \"flow_series\", \"diff_series\"]\n",
    "    runs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    data = load_images(base_path, targets, runs)\n",
    "\n",
    "    \n",
    "    # Configuration for inline display\n",
    "    plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "    plt.rcParams[\"animation.embed_limit\"] = 2048\n",
    "    plt.rcParams['figure.dpi'] = 150\n",
    "    %matplotlib inline\n",
    "    \n",
    "    # Define the number of columns and rows for the subplots\n",
    "    num_cols = len(targets)\n",
    "    num_rows = len(runs)\n",
    "    fig, axs = plt.subplots(ncols=num_cols, nrows=num_rows, figsize=(2 * num_cols, 2 * num_rows))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    images = []\n",
    "    for i in range(num_rows):\n",
    "        row_offset = i * num_cols\n",
    "        \n",
    "        y_pos = 1 - ((i + 1) / float(num_rows + 1))  # Adjust the vertical position\n",
    "        fig.text(0.01, y_pos, f\"{runs[i]}\", ha='right', va='center', fontsize=10, transform=fig.transFigure)\n",
    "        \n",
    "        if i == 0:       \n",
    "            axs[row_offset + 0].set(title=r\"$\\mathit{m}$\")\n",
    "            axs[row_offset + 1].set(title=r\"$\\mathit{m \\circ \\phi}$\")\n",
    "            axs[row_offset + 2].set(title=r\"$\\mathit{\\phi}$\")\n",
    "            axs[row_offset + 3].set(title=r\"$\\mathit{\\left| \\; (m \\circ \\phi) - f \\; \\right|}$\")\n",
    "    \n",
    "        ms, ws, fs, ds = data[i]\n",
    "    \n",
    "        for k in range(num_cols):\n",
    "            axs[row_offset + k].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[], aspect=\"equal\")\n",
    "    \n",
    "        images.append(axs[row_offset + 0].imshow(ms[0], animated=True))\n",
    "        images.append(axs[row_offset + 1].imshow(ws[0], animated=True))\n",
    "        images.append(axs[row_offset + 2].imshow(fs[0], animated=True))\n",
    "        images.append(axs[row_offset + 3].imshow(ds[0], animated=True))\n",
    "        \n",
    "    def animate(delta):\n",
    "        for local_i in range(len(runs)):\n",
    "            local_row_offset = local_i * num_cols\n",
    "            local_ms, local_ws, local_fs, local_ds = data[local_i]\n",
    "        \n",
    "            images[local_row_offset + 0].set_data(local_ms[delta])\n",
    "            images[local_row_offset + 1].set_data(local_ws[delta])\n",
    "            images[local_row_offset + 2].set_data(local_fs[delta])\n",
    "            images[local_row_offset + 3].set_data(local_ds[delta])\n",
    "    \n",
    "        return images\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(data[0][0]), blit=True)\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306f2b1668ff00",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "series_anim_main(TEST_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240d4e2-3c81-413e-8412-051e04017f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
