{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_NAME = \"criteria_warped\"\n",
    "SAMPLE_IDX = 1\n",
    "WANDB_PROJECT = \"temple/lung-registration\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bb56f8d68c923a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80c0295920dce081"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.ticker as ticker\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "from reg.transmorph import TransMorphModule\n",
    "from reg.data import LungDataModule"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T14:34:12.718476801Z",
     "start_time": "2024-05-26T14:34:12.647518011Z"
    }
   },
   "id": "cb19c88917b3914d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Series export"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddeaaaa8a1d07e8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d38b2d88ba9d04f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def sorted_files_in_directory(directory: str):\n",
    "    run_ids = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    runs = [(d, os.path.join(directory, d)) for d in run_ids]\n",
    "    files = [(run_id, sorted(os.listdir(path_suffix), reverse=True)) for run_id, path_suffix in runs]\n",
    "    files_best = [(run_id, ff[0]) for run_id, ff in files]\n",
    "    return files_best"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e31ca5476bb42a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_best_model(model_path: str):\n",
    "    model = TransMorphModule.load_from_checkpoint(str(model_path), strict=True)\n",
    "    print(f\"{'=' * 5} Configuration summary {'=' * 92}\")\n",
    "    print(f\"\")\n",
    "    print(model.hparams)\n",
    "    print(f\"\")\n",
    "    print(\"=\" * 120)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bac0fd0ea1f13296"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setup_data_module():\n",
    "    n_available_cores = len(os.sched_getaffinity(0)) - 1\n",
    "    n_available_cores = 1 if n_available_cores == 0 else n_available_cores\n",
    "    data_module = LungDataModule(\n",
    "        root_dir=\"/media/agjvc_rad3/_TESTKOLLEKTIV/Daten/Daten\",\n",
    "        split=(0.7, 0.1, 0.2),\n",
    "        seed=42,\n",
    "        pin_memory=True,\n",
    "        num_workers=n_available_cores,\n",
    "    )\n",
    "    data_module.setup()\n",
    "    return data_module"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3c8bae0d1d48bd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_diff_series(warped_series: torch.Tensor, fixed_image: torch.Tensor):\n",
    "    abs_diff_series = torch.stack([torch.abs(w - fixed_image) for w in warped_series], dim=0)\n",
    "    return abs_diff_series"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa5808b577641b85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_flow_series(flow_series: torch.Tensor):\n",
    "    flow_series = torch.tanh(flow_series[:, :, :])\n",
    "    flows_x = (flow_series[:, :, :, 0] + 1) / 2\n",
    "    flows_y = (flow_series[:, :, :, 1] + 1) / 2\n",
    "    flows_z = flows_x * 0\n",
    "    flow_series = torch.stack([flows_x, flows_y, flows_z], dim=-1)\n",
    "    return flow_series"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a63b2f8d7322492"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_sample_from_dataloader(dataloader, sample_idx):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i == sample_idx or sample_idx is None:\n",
    "            return batch"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac14b95c5e854da1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_text_to_image(image, text, position=(10, 10), font_size=20, color=(255, 255, 255)):\n",
    "    pil_img = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "\n",
    "    return np.array(pil_img)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2d8f5b581370ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_images_to_directory(directory, images, cmap):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for idx, img in tqdm(enumerate(images), total=images.shape[0]):\n",
    "        img_path = os.path.join(directory, f\"{idx:0>3}.png\")\n",
    "\n",
    "        if cmap is not None:\n",
    "            if img.ndim == 3 and img.shape[2] == 1:\n",
    "                img = img.cpu().numpy()[:, :, 0]\n",
    "            plt.imsave(img_path, img, cmap=cmap)\n",
    "        else:\n",
    "            # Save the image directly if no colormap is used\n",
    "            img = img.permute(2, 0, 1)  # Change shape to (C, H, W)\n",
    "            save_image(img, img_path)\n",
    "\n",
    "        # Add the index as text to the image\n",
    "        img = Image.open(img_path)\n",
    "        img = add_text_to_image(np.array(img), f\"{idx:0>3}\")\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(img_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4739625fb68cb48d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Series export main"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efed0300c871cde1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main_series_export(test_name, sample_idx=None):\n",
    "    model_path = f\"../model_weights/test_{test_name}\"\n",
    "    eval_path = f\"../model_eval/test_{test_name}\"\n",
    "\n",
    "    data_module = setup_data_module()\n",
    "    dataloader = data_module.test_dataloader()\n",
    "\n",
    "    if sample_idx is None:\n",
    "        sample_idx = np.random.randint(0, 64)\n",
    "\n",
    "    dim = (3, 1, 2, 0)\n",
    "    moving_series = fetch_sample_from_dataloader(dataloader, sample_idx).cuda()\n",
    "    moving_series_exp = moving_series[0].permute(dim)\n",
    "    \n",
    "    all_runs = sorted_files_in_directory(model_path)\n",
    "    for run_id, path_suffix in all_runs:\n",
    "        run_model_path = os.path.join(os.path.join(model_path, run_id), path_suffix)\n",
    "    \n",
    "        # 1. Load best model\n",
    "        model = load_best_model(run_model_path)\n",
    "\n",
    "        # 2. Extract predictions and inputs\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            warped_series, flow_series, fixed_image = model(moving_series)\n",
    "    \n",
    "        warped_series = warped_series[0].permute(dim)\n",
    "        flow_series = flow_series[0].permute(dim)\n",
    "        fixed_image = fixed_image[0].permute(dim)[0]\n",
    "    \n",
    "        # 3. Compute series difference\n",
    "        diff_series = compute_diff_series(warped_series, fixed_image)\n",
    "    \n",
    "        # 4. Transform flow series\n",
    "        transformed_flow = compute_flow_series(flow_series)\n",
    "    \n",
    "        # 5. Save images and video\n",
    "        arr = [\n",
    "            (moving_series_exp, \"moving_series\", None),\n",
    "            (warped_series, \"warped_series\", None),\n",
    "            (transformed_flow, \"flow_series\", None),\n",
    "            (diff_series, \"diff_series\", \"magma\")\n",
    "        ]\n",
    "    \n",
    "        for images, name, cmap in arr:\n",
    "            save_images_to_directory(f\"{eval_path}/{run_id}/{name}\", images, cmap)\n",
    "\n",
    "        del warped_series, flow_series, fixed_image, transformed_flow, diff_series\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))\n",
    "\n",
    "    image_means = moving_series.mean(axis=(1, 2))\n",
    "    figsize=(16,5)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=figsize)\n",
    "    fig.set_tight_layout(True)\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    ax[0].set_title(\"Mean\")\n",
    "    ax[0].plot(image_means, \"-\", lw=1)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38f3a8c230587a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "main_series_export(TEST_NAME, SAMPLE_IDX)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaabaee1d1d9c5cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fetch measured values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49a52dfaa4373765"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c87eda0ef6707ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def to_string(x):\n",
    "    x = np.array(x)\n",
    "    x = x.flatten()\n",
    "    s = \"-\".join(x)\n",
    "    return s"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0af501155fd4050"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch measured values main"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59e007bcdc54f58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main_fetch_values(test_name):\n",
    "    api = wandb.Api()\n",
    "    runs_wandb = api.runs(WANDB_PROJECT)\n",
    "    runs_dict = {}\n",
    "    for run in runs_wandb:\n",
    "        if f\"test_{test_name}\" in run.tags:\n",
    "            run_dict = {}\n",
    "    \n",
    "            exclude_patterns = [\"weights\", \"gradients\", \"step\", \"_wandb\", \"_timestamp\", \"graph\", \"val_loss_epoch\", \"train_loss_epoch\"]\n",
    "            \n",
    "            # Update the dictionary while excluding keys with specific patterns\n",
    "            def should_include_key(key):\n",
    "                for pattern in exclude_patterns:\n",
    "                    if pattern in key:\n",
    "                        return False\n",
    "                return True\n",
    "            \n",
    "            # .summary contains the output keys/values for metrics like accuracy.\n",
    "            #  We call ._json_dict to omit large files \n",
    "            run_dict.update({f\"m_{k}\": v for k, v in run.summary._json_dict.items() if should_include_key(k)})\n",
    "    \n",
    "        \n",
    "            # .config contains the hyperparameters.\n",
    "            #  We remove special values that start with _.\n",
    "            run_dict.update(\n",
    "                {f\"h_{k}\": v for k,v in run.config.items()\n",
    "                  if not k.startswith(\"_\")})\n",
    "        \n",
    "            # .name is the human-readable name of the run.\n",
    "            runs_dict.update({run.name: run_dict})\n",
    "            \n",
    "    runs_df = pd.DataFrame(runs_dict)\n",
    "    runs_df = runs_df.transpose()\n",
    "    \n",
    "    runs_df[\"h_criteria_warped\"] = runs_df[\"h_criteria_warped\"].apply(to_string)\n",
    "    runs_df[\"h_criteria_flow\"] = runs_df[\"h_criteria_flow\"].apply(to_string)\n",
    "    runs_df[\"m_duration_hours\"] = runs_df[\"m__runtime\"] / 3600\n",
    "    runs_df.drop(columns=[\"m__runtime\"], inplace=True)\n",
    "    runs_df = runs_df.reindex(sorted(runs_df.columns), axis=1)\n",
    "    runs_df = runs_df.transpose()\n",
    "    return runs_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50ace40fe534899b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_fetch_values(TEST_NAME)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30a6623792376523"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Series mean intensity histogram"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38db01108a37c608"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def histogram_main(sample_idx):\n",
    "    CUT_OFF = 30 \n",
    "    \n",
    "    data_module = setup_data_module()\n",
    "    dataloader = data_module.test_dataloader()\n",
    "    \n",
    "    if sample_idx is None:\n",
    "        sample_idx = np.random.randint(0, 64)\n",
    "    \n",
    "    moving_series = fetch_sample_from_dataloader(dataloader, sample_idx)\n",
    "    \n",
    "    image_means = moving_series.mean(axis=(2, 3))[0,0][CUT_OFF:]\n",
    "    mean_of_means = torch.mean(image_means)\n",
    "    diff = torch.abs(image_means - mean_of_means)\n",
    "    _, max_diff_i = torch.topk(diff, 1, largest=True)\n",
    "    _, mean_i = torch.topk(diff, 1, largest=False)\n",
    "    _, max_i = torch.topk(image_means, 1)\n",
    "    \n",
    "    image_indices = np.array(list(range(0, len(image_means)))) + CUT_OFF\n",
    "    \n",
    "    figsize=(16,5)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    fig.set_tight_layout(True)\n",
    "    \n",
    "    ax.set_title(\"Mean\")\n",
    "    ax.plot(image_indices, image_means, \"-\", color='b', lw=1)\n",
    "    ax.axvline(x=max_diff_i + CUT_OFF, color='r', label=f\"peak at idx = {(max_diff_i + CUT_OFF).numpy()[0]}\")\n",
    "    ax.axhline(y=image_means[-1], color='g', linestyle=\"dashed\", label=\"last\")\n",
    "    ax.axhline(y=image_means[mean_i], color='g', linestyle=\"dashdot\", label=\"mean\")\n",
    "    ax.axhline(y=image_means[max_i], color='g', linestyle=\"dotted\", label=\"peak\")\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7aa716239391a504"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "histogram_main(SAMPLE_IDX)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6f753f7d258c3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Series animation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2342e04400ec91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1ba2c1128ee6816"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_images(base_path, targets, runs):\n",
    "    data = []\n",
    "    for run in runs:\n",
    "        run_data = []\n",
    "        for target in targets:\n",
    "            target_path = os.path.join(base_path, run, target)\n",
    "            images = []\n",
    "            for img_name in sorted(os.listdir(target_path)):\n",
    "                if img_name.endswith('.png'):\n",
    "                    img_path = os.path.join(target_path, img_name)\n",
    "                    img = Image.open(img_path)\n",
    "                    img_array = np.array(img)\n",
    "                    images.append(img_array)\n",
    "            run_data.append(images)\n",
    "        data.append(run_data)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88a0aaec9ce6abb1"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cf630a28da583d6d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def series_anim_main():\n",
    "    base_path = \"../model_eval/test_criteria_warped\"\n",
    "    targets = [\"moving_series\", \"warped_series\", \"flow_series\", \"diff_series\"]\n",
    "    runs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    data = load_images(base_path, targets, runs)\n",
    "\n",
    "    \n",
    "    # Configuration for inline display\n",
    "    plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "    plt.rcParams[\"animation.embed_limit\"] = 2048\n",
    "    plt.rcParams['figure.dpi'] = 150\n",
    "    %matplotlib inline\n",
    "    \n",
    "    # Define the number of columns and rows for the subplots\n",
    "    num_cols = len(targets)\n",
    "    num_rows = len(runs)\n",
    "    fig, axs = plt.subplots(ncols=num_cols, nrows=num_rows, figsize=(2 * num_cols, 2 * num_rows))\n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    images = []\n",
    "    for i in range(num_rows):\n",
    "        row_offset = i * num_cols\n",
    "        \n",
    "        y_pos = 1 - ((i + 1) / float(num_rows + 1))  # Adjust the vertical position\n",
    "        fig.text(0.01, y_pos, f\"{runs[i]}\", ha='right', va='center', fontsize=10, transform=fig.transFigure)\n",
    "        \n",
    "        if i == 0:       \n",
    "            axs[row_offset + 0].set(title=r\"$\\mathit{m}$\")\n",
    "            axs[row_offset + 1].set(title=r\"$\\mathit{m \\circ \\phi}$\")\n",
    "            axs[row_offset + 2].set(title=r\"$\\mathit{\\phi}$\")\n",
    "            axs[row_offset + 3].set(title=r\"$\\mathit{\\left| \\; (m \\circ \\phi) - f \\; \\right|}$\")\n",
    "    \n",
    "        ms, ws, fs, ds = data[i]\n",
    "    \n",
    "        for k in range(num_cols):\n",
    "            axs[row_offset + k].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[], aspect=\"equal\")\n",
    "    \n",
    "        images.append(axs[row_offset + 0].imshow(ms[0], animated=True))\n",
    "        images.append(axs[row_offset + 1].imshow(ws[0], animated=True))\n",
    "        images.append(axs[row_offset + 2].imshow(fs[0], animated=True))\n",
    "        images.append(axs[row_offset + 3].imshow(ds[0], animated=True))\n",
    "        \n",
    "    def animate(delta):\n",
    "        for local_i in range(len(runs)):\n",
    "            local_row_offset = local_i * num_cols\n",
    "            local_ms, local_ws, local_fs, local_ds = data[local_i]\n",
    "        \n",
    "            images[local_row_offset + 0].set_data(local_ms[delta])\n",
    "            images[local_row_offset + 1].set_data(local_ws[delta])\n",
    "            images[local_row_offset + 2].set_data(local_fs[delta])\n",
    "            images[local_row_offset + 3].set_data(local_ds[delta])\n",
    "    \n",
    "        return images\n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, animate, frames=len(data[0][0]), blit=True)\n",
    "    return ani"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18b8ce43a3ad59ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "series_anim_main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1306f2b1668ff00"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
