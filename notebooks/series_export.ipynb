{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_NAME = \"<group_name>\"\n",
    "MODEL_PATH = f\"../model_weights/test_{GROUP_NAME}\"\n",
    "EVAL_PATH = f\"../model_eval/test_{GROUP_NAME}\"\n",
    "SAMPLE_IDX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from reg.data import LungDataModule\n",
    "from reg.transmorph import TransMorphModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series export functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_files_in_directory(directory: str):\n",
    "    run_ids = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "    runs = [(d, os.path.join(directory, d)) for d in run_ids]\n",
    "    files = [(run_id, sorted(os.listdir(path_suffix), reverse=True)) for run_id, path_suffix in runs]\n",
    "    files_best = [(run_id, ff[0]) for run_id, ff in files]\n",
    "    return files_best\n",
    "\n",
    "def load_best_model(model_path: str):\n",
    "    model = TransMorphModule.load_from_checkpoint(str(model_path), strict=True)\n",
    "    print(f\"{'=' * 5} Configuration summary {'=' * 92}\")\n",
    "    print(f\"\")\n",
    "    print(model.hparams)\n",
    "    print(f\"\")\n",
    "    print(\"=\" * 120)\n",
    "    return model\n",
    "\n",
    "def setup_data_module():\n",
    "    n_available_cores = len(os.sched_getaffinity(0)) - 1\n",
    "    n_available_cores = 1 if n_available_cores == 0 else n_available_cores\n",
    "    data_module = LungDataModule(\n",
    "        root_dir=\"/media/agjvc_rad3/_TESTKOLLEKTIV/Daten/Daten\",\n",
    "        split=(0.7, 0.1, 0.2),\n",
    "        seed=42,\n",
    "        pin_memory=True,\n",
    "        num_workers=n_available_cores,\n",
    "    )\n",
    "    data_module.setup()\n",
    "    return data_module\n",
    "\n",
    "def compute_diff_series(warped_series: torch.Tensor, fixed_image: torch.Tensor):\n",
    "    abs_diff_series = torch.stack([torch.abs(w - fixed_image) for w in warped_series], dim=0)\n",
    "    return abs_diff_series\n",
    "\n",
    "def compute_flow_series(flow_series: torch.Tensor):\n",
    "    flow_series = torch.tanh(flow_series[:, :, :])\n",
    "    flows_x = (flow_series[:, :, :, 0] + 1) / 2\n",
    "    flows_y = (flow_series[:, :, :, 1] + 1) / 2\n",
    "    flows_z = flows_x * 0\n",
    "    flow_series = torch.stack([flows_x, flows_y, flows_z], dim=-1)\n",
    "    return flow_series\n",
    "\n",
    "def fetch_sample_from_dataloader(dataloader, sample_idx):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i == sample_idx or sample_idx is None:\n",
    "            return batch\n",
    "        \n",
    "def add_text_to_image(image, text, position=(10, 10), font_size=20, color=(255, 255, 255)):\n",
    "    pil_img = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", font_size)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "    draw.text(position, text, font=font, fill=color)\n",
    "    return np.array(pil_img)\n",
    "\n",
    "def save_images_to_directory(directory, images, cmap):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for idx, img in tqdm(enumerate(images), total=images.shape[0]):\n",
    "        img_path = os.path.join(directory, f\"{idx:0>3}.png\")\n",
    "        if cmap is not None:\n",
    "            if img.ndim == 3 and img.shape[2] == 1:\n",
    "                img = img.cpu().numpy()[:, :, 0]\n",
    "            plt.imsave(img_path, img, cmap=cmap)\n",
    "        else:\n",
    "            img = img.permute(2, 0, 1)\n",
    "            save_image(img, img_path)\n",
    "        img = Image.open(img_path)\n",
    "        img = add_text_to_image(np.array(img), f\"{idx:0>3}\")\n",
    "        img = Image.fromarray(img)\n",
    "        img.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_series_export(model_path, eval_path, sample_idx=None):\n",
    "    data_module = setup_data_module()\n",
    "    dataloader = data_module.test_dataloader()\n",
    "\n",
    "    if sample_idx is None:\n",
    "        sample_idx = np.random.randint(0, 64)\n",
    "\n",
    "    dim = (3, 1, 2, 0)\n",
    "    moving_series = fetch_sample_from_dataloader(dataloader, sample_idx).cuda()\n",
    "    moving_series_exp = moving_series[0].permute(dim)\n",
    "    \n",
    "    all_runs = sorted_files_in_directory(model_path)\n",
    "    for run_id, path_suffix in all_runs:\n",
    "        run_model_path = os.path.join(os.path.join(model_path, run_id), path_suffix)\n",
    "    \n",
    "        # 1. Load best model\n",
    "        model = load_best_model(run_model_path)\n",
    "\n",
    "        # 2. Extract predictions and inputs\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            warped_series, flow_series, fixed_image = model(moving_series)\n",
    "    \n",
    "        warped_series = warped_series[0].permute(dim)\n",
    "        flow_series = flow_series[0].permute(dim)\n",
    "        fixed_image = fixed_image[0].permute(dim)[0]\n",
    "    \n",
    "        # 3. Compute series difference\n",
    "        diff_series = compute_diff_series(warped_series, fixed_image)\n",
    "    \n",
    "        # 4. Transform flow series\n",
    "        transformed_flow = compute_flow_series(flow_series)\n",
    "    \n",
    "        # 5. Save images and video\n",
    "        arr = [\n",
    "            (moving_series_exp, \"moving_series\", None),\n",
    "            (warped_series, \"warped_series\", None),\n",
    "            (transformed_flow, \"flow_series\", None),\n",
    "            (diff_series, \"diff_series\", \"magma\")\n",
    "        ]\n",
    "    \n",
    "        for images, name, cmap in arr:\n",
    "            save_images_to_directory(f\"{eval_path}/{run_id}/{name}\", images, cmap)\n",
    "\n",
    "        del warped_series, flow_series, fixed_image, transformed_flow, diff_series\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"torch.cuda.memory_allocated: %fGB\"%(torch.cuda.memory_allocated(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.memory_reserved: %fGB\"%(torch.cuda.memory_reserved(0)/1024/1024/1024))\n",
    "        print(\"torch.cuda.max_memory_reserved: %fGB\"%(torch.cuda.max_memory_reserved(0)/1024/1024/1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "main_series_export(MODEL_PATH, EVAL_PATH, SAMPLE_IDX)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
